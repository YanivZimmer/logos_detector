{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 2: Enhanced Template Matching for New Logo Detection\n",
        "\n",
        "This notebook implements an enhanced template matching approach for detecting new logos without training.\n",
        "\n",
        "## Enhanced Template Matching Overview:\n",
        "- **Classical Computer Vision**: Uses image correlation and matching\n",
        "- **Advantages**: \n",
        "  - No training required\n",
        "  - Fast inference\n",
        "  - Works with single example\n",
        "  - Interpretable results\n",
        "- **Enhancements**:\n",
        "  - Multi-scale template matching\n",
        "  - Rotation-invariant matching\n",
        "  - Feature-based matching (ORB, SIFT)\n",
        "  - Template database management\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better visualizations\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Section 2 Data and Extract Templates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Section 2 data\n",
        "SECTION2_ROOT = Path(\"raw_data/logos-dataset-section-2\")\n",
        "section2_image = SECTION2_ROOT / \"Adidas_38.jpg\"\n",
        "section2_label = SECTION2_ROOT / \"Adidas_38.txt\"\n",
        "\n",
        "# Load image\n",
        "img = Image.open(section2_image)\n",
        "img_array = np.array(img)\n",
        "img_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
        "img_gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "print(f\"Image size: {img.size}\")\n",
        "\n",
        "# Load annotations\n",
        "with open(section2_label, 'r') as f:\n",
        "    annotations = f.readlines()\n",
        "\n",
        "new_classes = []\n",
        "templates = []\n",
        "img_width, img_height = img.size\n",
        "\n",
        "for ann in annotations:\n",
        "    parts = ann.strip().split()\n",
        "    if len(parts) >= 5:\n",
        "        class_name = parts[0]\n",
        "        if class_name not in new_classes:\n",
        "            new_classes.append(class_name)\n",
        "        \n",
        "        x_center, y_center, width, height = [float(x) for x in parts[1:5]]\n",
        "        x1 = int((x_center - width/2) * img_width)\n",
        "        y1 = int((y_center - height/2) * img_height)\n",
        "        x2 = int((x_center + width/2) * img_width)\n",
        "        y2 = int((y_center + height/2) * img_height)\n",
        "        \n",
        "        # Extract template with padding\n",
        "        padding = 10\n",
        "        x1 = max(0, x1 - padding)\n",
        "        y1 = max(0, y1 - padding)\n",
        "        x2 = min(img_width, x2 + padding)\n",
        "        y2 = min(img_height, y2 + padding)\n",
        "        \n",
        "        template = img_gray[y1:y2, x1:x2]\n",
        "        template_color = img_array[y1:y2, x1:x2]\n",
        "        \n",
        "        templates.append({\n",
        "            'class': class_name,\n",
        "            'template_gray': template,\n",
        "            'template_color': template_color,\n",
        "            'bbox': (x1, y1, x2, y2)\n",
        "        })\n",
        "\n",
        "print(f\"Extracted {len(templates)} templates for classes: {new_classes}\")\n",
        "\n",
        "# Visualize extracted templates\n",
        "fig, axes = plt.subplots(1, len(templates), figsize=(5*len(templates), 5))\n",
        "if len(templates) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for idx, template_info in enumerate(templates):\n",
        "    axes[idx].imshow(template_info['template_color'])\n",
        "    axes[idx].axis('off')\n",
        "    axes[idx].set_title(f\"{template_info['class']}\\n{template_info['template_gray'].shape}\", \n",
        "                       fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('section2_templates_extracted.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def enhanced_template_matching(img_gray, templates, threshold=0.6, scales=[0.5, 0.75, 1.0, 1.25, 1.5, 2.0]):\n",
        "    \"\"\"Enhanced multi-scale template matching with rotation\"\"\"\n",
        "    detections = []\n",
        "    \n",
        "    for template_info in templates:\n",
        "        template = template_info['template_gray']\n",
        "        class_name = template_info['class']\n",
        "        \n",
        "        best_match_val = 0\n",
        "        best_match_loc = None\n",
        "        best_scale = 1.0\n",
        "        best_angle = 0\n",
        "        \n",
        "        # Multi-scale matching\n",
        "        for scale in scales:\n",
        "            h, w = template.shape[:2]\n",
        "            scaled_w = int(w * scale)\n",
        "            scaled_h = int(h * scale)\n",
        "            \n",
        "            if scaled_h > img_gray.shape[0] or scaled_w > img_gray.shape[1]:\n",
        "                continue\n",
        "            \n",
        "            scaled_template = cv2.resize(template, (scaled_w, scaled_h))\n",
        "            \n",
        "            # Try different rotation angles\n",
        "            for angle in [0, 15, -15, 30, -30]:\n",
        "                if angle != 0:\n",
        "                    M = cv2.getRotationMatrix2D((scaled_w/2, scaled_h/2), angle, 1.0)\n",
        "                    rotated_template = cv2.warpAffine(scaled_template, M, (scaled_w, scaled_h))\n",
        "                else:\n",
        "                    rotated_template = scaled_template\n",
        "                \n",
        "                # Template matching\n",
        "                result = cv2.matchTemplate(img_gray, rotated_template, cv2.TM_CCOEFF_NORMED)\n",
        "                min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
        "                \n",
        "                if max_val > best_match_val:\n",
        "                    best_match_val = max_val\n",
        "                    best_match_loc = max_loc\n",
        "                    best_scale = scale\n",
        "                    best_angle = angle\n",
        "        \n",
        "        if best_match_val >= threshold and best_match_loc is not None:\n",
        "            h, w = template.shape[:2]\n",
        "            x1 = best_match_loc[0]\n",
        "            y1 = best_match_loc[1]\n",
        "            x2 = x1 + int(w * best_scale)\n",
        "            y2 = y1 + int(h * best_scale)\n",
        "            \n",
        "            detections.append({\n",
        "                'class': class_name,\n",
        "                'bbox': (x1, y1, x2, y2),\n",
        "                'confidence': float(best_match_val),\n",
        "                'scale': best_scale,\n",
        "                'angle': best_angle\n",
        "            })\n",
        "    \n",
        "    return detections\n",
        "\n",
        "# Run enhanced template matching\n",
        "print(\"Running enhanced template matching...\")\n",
        "detections = enhanced_template_matching(img_gray, templates, threshold=0.5)\n",
        "\n",
        "print(f\"\\nFound {len(detections)} detections:\")\n",
        "for det in detections:\n",
        "    print(f\"  {det['class']}: {det['confidence']:.3f} (scale: {det['scale']:.2f}, angle: {det['angle']}Â°)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Feature-Based Matching (ORB)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def feature_based_matching(img_gray, templates, min_match_count=10):\n",
        "    \"\"\"Feature-based matching using ORB\"\"\"\n",
        "    # Initialize ORB detector\n",
        "    orb = cv2.ORB_create()\n",
        "    \n",
        "    # Find keypoints and descriptors in the image\n",
        "    kp_img, des_img = orb.detectAndCompute(img_gray, None)\n",
        "    \n",
        "    detections = []\n",
        "    \n",
        "    for template_info in templates:\n",
        "        template = template_info['template_gray']\n",
        "        class_name = template_info['class']\n",
        "        \n",
        "        # Find keypoints and descriptors in template\n",
        "        kp_template, des_template = orb.detectAndCompute(template, None)\n",
        "        \n",
        "        if des_template is None or des_img is None:\n",
        "            continue\n",
        "        \n",
        "        # Match descriptors\n",
        "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "        matches = bf.match(des_template, des_img)\n",
        "        matches = sorted(matches, key=lambda x: x.distance)\n",
        "        \n",
        "        if len(matches) >= min_match_count:\n",
        "            # Get matched keypoints\n",
        "            src_pts = np.float32([kp_template[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
        "            dst_pts = np.float32([kp_img[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
        "            \n",
        "            # Find homography\n",
        "            M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "            \n",
        "            if M is not None:\n",
        "                h, w = template.shape\n",
        "                pts = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)\n",
        "                dst = cv2.perspectiveTransform(pts, M)\n",
        "                \n",
        "                # Get bounding box\n",
        "                x_coords = [pt[0][0] for pt in dst]\n",
        "                y_coords = [pt[0][1] for pt in dst]\n",
        "                x1, y1 = int(min(x_coords)), int(min(y_coords))\n",
        "                x2, y2 = int(max(x_coords)), int(max(y_coords))\n",
        "                \n",
        "                confidence = len(matches) / 50.0  # Normalize\n",
        "                confidence = min(1.0, confidence)\n",
        "                \n",
        "                detections.append({\n",
        "                    'class': class_name,\n",
        "                    'bbox': (x1, y1, x2, y2),\n",
        "                    'confidence': confidence,\n",
        "                    'matches': len(matches),\n",
        "                    'method': 'ORB'\n",
        "                })\n",
        "    \n",
        "    return detections\n",
        "\n",
        "# Run feature-based matching\n",
        "print(\"Running feature-based matching (ORB)...\")\n",
        "orb_detections = feature_based_matching(img_gray, templates, min_match_count=10)\n",
        "\n",
        "print(f\"\\nORB found {len(orb_detections)} detections:\")\n",
        "for det in orb_detections:\n",
        "    print(f\"  {det['class']}: {det['confidence']:.3f} ({det['matches']} matches)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualize All Matching Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine all detections\n",
        "all_detections = {\n",
        "    'template_matching': detections,\n",
        "    'orb_matching': orb_detections\n",
        "}\n",
        "\n",
        "# Visualize results\n",
        "fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
        "\n",
        "# Ground truth\n",
        "axes[0].imshow(img)\n",
        "axes[0].axis('off')\n",
        "axes[0].set_title('Ground Truth', fontsize=14, fontweight='bold')\n",
        "\n",
        "img_width, img_height = img.size\n",
        "for ann in annotations:\n",
        "    parts = ann.strip().split()\n",
        "    if len(parts) >= 5:\n",
        "        class_name = parts[0]\n",
        "        x_center, y_center, width, height = [float(x) for x in parts[1:5]]\n",
        "        x = (x_center - width/2) * img_width\n",
        "        y = (y_center - height/2) * img_height\n",
        "        w = width * img_width\n",
        "        h = height * img_height\n",
        "        from matplotlib.patches import Rectangle\n",
        "        rect = Rectangle((x, y), w, h, linewidth=3, edgecolor='red', facecolor='none')\n",
        "        axes[0].add_patch(rect)\n",
        "        axes[0].text(x, y-10, class_name, color='red', fontsize=10, fontweight='bold',\n",
        "                    bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.8))\n",
        "\n",
        "# Template matching results\n",
        "axes[1].imshow(img)\n",
        "axes[1].axis('off')\n",
        "axes[1].set_title('Template Matching Results', fontsize=14, fontweight='bold')\n",
        "\n",
        "for det in detections:\n",
        "    x1, y1, x2, y2 = det['bbox']\n",
        "    from matplotlib.patches import Rectangle\n",
        "    rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, \n",
        "                    edgecolor='green', facecolor='none')\n",
        "    axes[1].add_patch(rect)\n",
        "    axes[1].text(x1, y1-5, f\"{det['class']} {det['confidence']:.2f}\", \n",
        "                color='green', fontsize=10, fontweight='bold',\n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
        "\n",
        "# ORB matching results\n",
        "axes[2].imshow(img)\n",
        "axes[2].axis('off')\n",
        "axes[2].set_title('ORB Feature Matching Results', fontsize=14, fontweight='bold')\n",
        "\n",
        "for det in orb_detections:\n",
        "    x1, y1, x2, y2 = det['bbox']\n",
        "    from matplotlib.patches import Rectangle\n",
        "    rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, \n",
        "                    edgecolor='blue', facecolor='none')\n",
        "    axes[2].add_patch(rect)\n",
        "    axes[2].text(x1, y1-5, f\"{det['class']} {det['confidence']:.2f}\", \n",
        "                 color='blue', fontsize=10, fontweight='bold',\n",
        "                 bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('section2_enhanced_template_matching.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Enhanced template matching results saved to section2_enhanced_template_matching.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results\n",
        "template_matching_results = {\n",
        "    'new_classes': new_classes,\n",
        "    'template_matching_detections': len(detections),\n",
        "    'orb_detections': len(orb_detections),\n",
        "    'all_detections': all_detections,\n",
        "    'model_type': 'Enhanced Template Matching'\n",
        "}\n",
        "\n",
        "with open('section2_template_matching_results.json', 'w') as f:\n",
        "    json.dump(template_matching_results, f, indent=2)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ENHANCED TEMPLATE MATCHING RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Target classes: {new_classes}\")\n",
        "print(f\"Template matching detections: {len(detections)}\")\n",
        "print(f\"ORB feature matching detections: {len(orb_detections)}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nEnhanced template matching results saved to section2_template_matching_results.json\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
